{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f204b71d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wrangle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TweedieRegressor\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrangle\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wrangle'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee43d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_df.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f18674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e05e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = wrangle.split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f46bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_visual(df):\n",
    "    '''\n",
    "    creates histplots for all of my columns\n",
    "    '''\n",
    "    plt.figure(figsize=(25,15))\n",
    "    plt.xticks(rotation = 45)\n",
    "    for i, col in enumerate(df):\n",
    "\n",
    "        plt.title(col)\n",
    "        sns.histplot(df[col])\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e44924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univariate_visual(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f3836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_charts(train,columns_list, target):\n",
    "    '''\n",
    "    Creates and shows visuals for Correlation tests \n",
    "    '''\n",
    "    plt.figure(figsize=(14,3))\n",
    "    plt.suptitle('Bivariate Exploration: The Strongest Correlators of Wine Quality')\n",
    "    for i, col in enumerate(train[columns_list]):\n",
    "        if col != target:\n",
    "\n",
    "            sns.regplot(data = train, x = col, y = target, scatter_kws={'alpha': 0.1}, line_kws={'color': 'red'})\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df.select_dtypes(exclude=['object']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = columns_list.pop(len(columns_list) -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638699cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e3c49",
   "metadata": {},
   "source": [
    "time to throw has a neutral correlation towards our target variable\n",
    "avg comp air yards has a slightly negative correlation towards our target variable\n",
    "avt att air yards has a negative correlation towards our target variable\n",
    "avg air yard diff has a positive correlation towards our target variable\n",
    "aggressive has a negative correlation towards our target variable\n",
    "longest comp air dist has a positive correlation towards our target variable\n",
    "air yards to sticks has a slightly negative correlation towards our target variable\n",
    "pass attempts have a strong positive correlation towards our target variable\n",
    "total yards has a strong positive correlation towards our target variable\n",
    "touchdowns has a strong positive correlation towards our target variable\n",
    "interceptions has a positive correlation towards our target variable\n",
    "pass rating has a positive correlation towards our target variable\n",
    "completion percentage has a positive correlation towars our target variable\n",
    "exp completion percentage has a positive correlation towards our target variable\n",
    "completion pct abv exp has a positive correlation towards our target variable\n",
    "year has a neutral correlation with out target variable\n",
    "first round has a slightly positive correlation with our target variable\n",
    "div round has a slightly positive correlation with our target variable\n",
    "conference champ has a slightly positive correlation with our target variable\n",
    "superbowl has a neutral correlation with our target variable\n",
    "won superbowl has a slightly positive correlation with our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list.append('win')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f168a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation_charts(train,columns_list, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac7767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_tests(train, columns_list, target):\n",
    "    '''\n",
    "    Runs a correlation test on dataframe features vs target variable\n",
    "    '''\n",
    "    corr_df = pd.DataFrame({'feature': [],\n",
    "                        'r': [],\n",
    "                       'p': []})\n",
    "    for i, col in enumerate(train[columns_list]):\n",
    "        r, p = stats.pearsonr(train[col], train[target])\n",
    "        corr_df.loc[i] = [col, abs(r), p]\n",
    "    to_return = corr_df.sort_values(by='r', ascending=False)\n",
    "    to_return['target'] = target\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72004b27",
   "metadata": {},
   "source": [
    "p value was greater than alpha for:\n",
    "> - year\n",
    "> - superbowl\n",
    "> - avg_comp_air_yds\n",
    "> - won_superbowl\n",
    "> - air_yds_to_sticks\n",
    "> - time_to_throw\n",
    "> - avg_air_yard_diff\n",
    "> - avg_att_air_yards\n",
    "> - conf_champ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93def835",
   "metadata": {},
   "source": [
    "- We will use RMSE as our evaluation metric\n",
    "\n",
    "** by using baseline as an evaluation metric we can be accurate to within 6.9% <br>\n",
    "** 6.9% will be the baseline RMSE we will use for this project <br>\n",
    "<br>\n",
    "** I will be evaluating models developed using four different model types and various hyperparameter configurations * Models will be evaluated on train and validate data * The model that performs the best will then be evaluated on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570b777",
   "metadata": {},
   "source": [
    "Feature we are moving forward with\n",
    "> - total_yds\n",
    "> - pass_att\n",
    "> - td\n",
    "> - pass_rating\n",
    "> - completion_pct\n",
    "> - exp_completion_pct\n",
    "> - completion_pct_abv_exp\n",
    "> - lon_comp_air_dist\n",
    "> - int\n",
    "> - div_round\n",
    "> - aggressive\n",
    "> - first_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5248d7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation_tests(train, columns_list, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = wrangle.get_X_train_val_test(train,validate, test, columns_list,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f71a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train,\n",
    "               validate,\n",
    "               test,\n",
    "               cols = columns_list):\n",
    "    '''Takes in train, validate, and test set, and outputs scaled versions of the columns that were sent in as dataframes'''\n",
    "    #Make copies for scaling\n",
    "    train_scaled = train.copy() #Ah, making a copy of the df and then overwriting the data in .transform() to remove warning message\n",
    "    validate_scaled = validate.copy()\n",
    "    test_scaled = test.copy()\n",
    "    #Initiate scaler, using Min max scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    #Fit to train only\n",
    "    scaler.fit(train[cols])\n",
    "    #Creates scaled dataframes of train, validate, and test. This will still preserve columns that were not sent in initially.\n",
    "    train_scaled[cols] = scaler.transform(train[cols])\n",
    "    validate_scaled[cols] = scaler.transform(validate[cols])\n",
    "    test_scaled[cols] = scaler.transform(test[cols])\n",
    "\n",
    "    return train_scaled, validate_scaled, test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test = wrangle.scale_data(X_train,\n",
    "               X_validate,\n",
    "               X_test,\n",
    "               cols = columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1491e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1, df2, df3 = wrangle.get_model_numbers(X_train, X_validate, X_test, y_train, y_validate, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113cd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8635e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
